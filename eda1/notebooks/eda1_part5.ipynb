{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7d5ebc",
   "metadata": {},
   "source": [
    "# Sequence Embeddings dos Hinos da ICM\n",
    "Este notebook explora técnicas de sequence embeddings para representar os textos completos dos hinos da coletânea principal da Igreja Cristã Maranata.\n",
    "\n",
    "O objetivo é aplicar modelos de embeddings de sentenças, calcular similaridade, realizar agrupamentos, buscar hinos por texto e extrair tópicos com BERTopic.\n",
    "\n",
    "---\n",
    "**Conteúdo do notebook:**\n",
    "- Carregamento do modelo SentenceTransformer e dos dados tratados\n",
    "- Geração de embeddings para cada hino\n",
    "- Cálculo de similaridade entre hinos\n",
    "- Visualização de matrizes de similaridade\n",
    "- Redução de dimensionalidade (t-SNE, UMAP)\n",
    "- Agrupamento de hinos por KMeans\n",
    "- Busca de hinos por texto\n",
    "- Extração de tópicos com BERTopic\n",
    "- Visualização dos agrupamentos e tópicos\n",
    "- Salvamento dos resultados para uso futuro\n",
    "\n",
    "Este material é público e pode ser compartilhado para fins de pesquisa, estudo ou divulgação cultural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185da0b4",
   "metadata": {},
   "source": [
    "# Parte 4 - Sequence embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ffb936",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Carregamento do modelo SentenceTransformer para geração de embeddings de sentenças dos hinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Diversas opções de modelos:\n",
    "# model = SentenceTransformer(\"distiluse-base-multilingual-cased-v2\")\n",
    "# model = SentenceTransformer(\"neuralmind/bert-base-portuguese-cased\")\n",
    "# model = SentenceTransformer(\"rufimelo/Legal-BERTimbau-sts-base\")  # português brasileiro\n",
    "model = SentenceTransformer(\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")  # mais leve e eficiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0bfba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Carregamento dos dados dos hinos já enriquecidos com embeddings anteriores, prontos para análise de sentenças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f1bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hinos_analise: pd.DataFrame = pd.read_pickle(\n",
    "    \"..\\\\assets\\\\hinos_analise_word_embeddings.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27601c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Geração dos embeddings de sentenças para cada hino, representando o texto completo em um vetor denso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1863c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# cria embeddings diretamente para cada hino (texto inteiro)\n",
    "embeddings = model.encode(hinos_analise[\"texto_limpo\"].tolist(), show_progress_bar=True)\n",
    "X_sent = np.array(embeddings)\n",
    "hinos_analise[\"sent_embeddings\"] = list(X_sent)\n",
    "\n",
    "print(X_sent.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08923b48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Cálculo da similaridade entre hinos usando os embeddings de sentenças, identificação dos hinos mais semelhantes ao hino de referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1804e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(X_sent)\n",
    "\n",
    "# hinos mais semelhantes ao hino 443\n",
    "similarities = list(enumerate(similarity_matrix[443]))\n",
    "similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Mais parecidos com o hino 443:\")\n",
    "for idx, score in similarities[1:6]:\n",
    "    print(f\"Hino {idx}: {hinos_analise['nome'].iloc[idx]} → similaridade {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f689f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Visualização da matriz de similaridade entre hinos utilizando heatmap para facilitar a análise dos padrões de similaridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "similarity_matrix_df = pd.DataFrame(\n",
    "    similarity_matrix, index=hinos_analise.index, columns=hinos_analise.index\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(similarity_matrix_df, cmap=\"viridis\", annot=False, cbar=True)\n",
    "plt.title(\"Similaridade entre hinos (Sentence Embeddings)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47569a4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Redução de dimensionalidade dos embeddings dos hinos utilizando t-SNE e UMAP para visualização e agrupamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0dab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,  # 2D\n",
    "    perplexity=30,\n",
    "    random_state=42,\n",
    ")\n",
    "X_tsne = tsne.fit_transform(X_sent)\n",
    "\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "X_umap = umap_model.fit_transform(X_sent)\n",
    "\n",
    "hinos_analise[\"sent_tsne1\"] = X_tsne[:, 0]\n",
    "hinos_analise[\"sent_tsne2\"] = X_tsne[:, 1]\n",
    "\n",
    "hinos_analise[\"sent_umap1\"] = X_umap[:, 0]\n",
    "hinos_analise[\"sent_umap2\"] = X_umap[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "sns.scatterplot(data=hinos_analise, x=\"sent_tsne1\", y=\"sent_tsne2\", ax=ax[0])\n",
    "ax[0].set_title(\"t-SNE\")\n",
    "sns.scatterplot(data=hinos_analise, x=\"sent_umap1\", y=\"sent_umap2\", ax=ax[1])\n",
    "ax[1].set_title(\"UMAP\")\n",
    "plt.suptitle(\"Mapa dos hinos com Sentence Embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d36cc7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Análise de agrupamento dos hinos utilizando KMeans, avaliação do número ideal de clusters com o coeficiente de Silhouette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "range_n_clusters = range(2, 12)\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_umap)\n",
    "    score = silhouette_score(X_umap, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"k = {k}, silhouette = {score:.4f}\")\n",
    "\n",
    "# Visualiza o resultado\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker=\"o\")\n",
    "plt.title(\"Análise de Silhouette para seleção de k\")\n",
    "plt.xlabel(\"Número de clusters (k)\")\n",
    "plt.ylabel(\"Coeficiente médio de Silhouette\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c4d9f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Visualização dos agrupamentos dos hinos por embeddings reduzidos, utilizando scatterplot para UMAP e clusters do KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# número de clusters (experimente, ex.: 4 ou 6)\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "hinos_analise[\"sent_cluster\"] = kmeans.fit_predict(X_umap)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=hinos_analise,\n",
    "    x=\"sent_umap1\",\n",
    "    y=\"sent_umap2\",\n",
    "    hue=\"sent_cluster\",\n",
    "    palette=\"tab10\",\n",
    "    s=80,\n",
    ")\n",
    "plt.title(\"Mapa dos hinos com Sentence Embeddings (UMAP)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a400fa9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Análise dos termos mais frequentes em cada cluster e visualização da distribuição dos hinos por cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5543c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for c in sorted(hinos_analise[\"sent_cluster\"].unique()):\n",
    "    cluster_tokens = hinos_analise.loc[\n",
    "        hinos_analise[\"sent_cluster\"] == c, \"tokens_no_stops\"\n",
    "    ].sum()\n",
    "    top_terms = Counter(cluster_tokens).most_common(10)\n",
    "    print(f\"\\nCluster {c}:\")\n",
    "    print([t for t, _ in top_terms])\n",
    "    print(hinos_analise.loc[hinos_analise[\"sent_cluster\"] == c, \"nome\"][:5])\n",
    "\n",
    "print(hinos_analise[\"sent_cluster\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f002f16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Busca de hinos por similaridade textual, utilizando embeddings para encontrar os hinos mais próximos de uma consulta em linguagem natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"a palavra é alimento para a alma\"\n",
    "query_vec = model.encode([query])\n",
    "\n",
    "scores = cosine_similarity(query_vec, X_sent)[0]\n",
    "top_idx = np.argsort(scores)[::-1][:10]\n",
    "\n",
    "print(\"Top hinos para a busca:\")\n",
    "for i in top_idx:\n",
    "    print(f\"Hino {i}: {hinos_analise['nome'].iloc[i]} → score {scores[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ccad2c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Extração de tópicos dos hinos utilizando BERTopic, atribuição dos tópicos aos hinos e visualização da distribuição dos tópicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897420ba",
   "metadata": {},
   "source": [
    "# Tópicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc7edc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Visualização dos agrupamentos dos hinos por tópicos extraídos com BERTopic, utilizando scatterplot para UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d826129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "# Criar o modelo BERTopic\n",
    "topic_model = BERTopic(embedding_model=model)\n",
    "\n",
    "# Treinar modelo\n",
    "topics, probs = topic_model.fit_transform(hinos_analise[\"texto_limpo\"])\n",
    "\n",
    "# Associar tópicos ao DataFrame\n",
    "hinos_analise[\"BERT_topic\"] = topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a076792",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Visualização dos agrupamentos dos hinos por tópicos em diferentes projeções (UMAP), utilizando BERTopic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDistribuição de tópicos por hino:\")\n",
    "print(hinos_analise[\"BERT_topic\"].value_counts())\n",
    "\n",
    "# Mostrar os tópicos descobertos\n",
    "print(\"\\nTópicos extraídos:\")\n",
    "for topic_num in set(topics):\n",
    "    if (\n",
    "        topic_num != -1\n",
    "    ):  # -1 significa \"outlier\" (documento não encaixou em nenhum cluster)\n",
    "        palavras = topic_model.get_topic(topic_num)\n",
    "        print(f\"Tópico {topic_num}:\")\n",
    "        print([word for word, _ in palavras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5bfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# número de clusters (experimente, ex.: 4 ou 6)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=hinos_analise,\n",
    "    x=\"sent_umap1\",\n",
    "    y=\"sent_umap2\",\n",
    "    hue=\"BERT_topic\",\n",
    "    palette=\"tab10\",\n",
    "    s=80,\n",
    ")\n",
    "plt.title(\"Mapa dos hinos com Sentence Embeddings (BERTopic)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96957d91",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A seguir:** Salvamento dos resultados e informações enriquecidas dos hinos para uso em análises futuras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ac1cf",
   "metadata": {},
   "source": [
    "# Salvamento de informações novas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac930e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Fim do notebook:** Finalização do processamento, com os dados prontos para exportação e uso em outras análises ou aplicações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hinos_analise.to_pickle(\"..\\\\assets\\\\hinos_analise_embeddings_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_df.to_pickle(\"..\\\\assets\\\\similarity_matrix_sentence_embeddings.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
