{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27384fab",
   "metadata": {},
   "source": [
    "# Parte 7 - Análise de Emoção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f00782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "hinos_analise: pd.DataFrame = pd.read_pickle(\"..\\\\assets\\\\hinos_analise_tokens.pkl\")\n",
    "\n",
    "# Carregar modelo multilíngue de emoções\n",
    "model_name = \"pysentimiento/bert-pt-emotion\"\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model_name,\n",
    "    tokenizer=model_name,\n",
    "    top_k=None,  # Substitui return_all_scores=True (depreciado)\n",
    "    max_length=512,  # Limite máximo de tokens do BERT\n",
    "    truncation=True,  # Trunca textos longos automaticamente\n",
    "    device=-1  # Força uso da CPU para evitar problemas de memória\n",
    ")\n",
    "\n",
    "# Função para truncar texto se necessário\n",
    "def truncar_texto(texto, max_tokens=400):\n",
    "    \"\"\"Trunca o texto para não exceder o limite do modelo\"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Tokeniza e verifica o tamanho\n",
    "    tokens = classifier.tokenizer.encode(texto, add_special_tokens=True, max_length=max_tokens, truncation=True)\n",
    "    # Decodifica os tokens truncados\n",
    "    texto_truncado = classifier.tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    return texto_truncado\n",
    "\n",
    "# Classificar emoções com tratamento de erro\n",
    "def analisar_emocoes(texto):\n",
    "    try:\n",
    "        if not isinstance(texto, str) or len(texto.strip()) == 0:\n",
    "            return {}\n",
    "        \n",
    "        # Truncar texto se necessário\n",
    "        texto_processado = truncar_texto(texto)\n",
    "        \n",
    "        # Classificar emoções\n",
    "        resultado = classifier(texto_processado)\n",
    "        \n",
    "        # O resultado é uma lista de listas, pegamos o primeiro elemento\n",
    "        if isinstance(resultado, list) and len(resultado) > 0:\n",
    "            emocoes_lista = resultado[0]  # Primeira (e única) amostra\n",
    "            if isinstance(emocoes_lista, list):\n",
    "                # Converter lista de dicts em dict plano {emoção: score}\n",
    "                return {r[\"label\"]: r[\"score\"] for r in emocoes_lista}\n",
    "        \n",
    "        return {}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar texto: {str(e)[:100]}...\")\n",
    "        return {}\n",
    "\n",
    "# Verificar alguns textos antes de processar tudo\n",
    "print(\"Verificando tamanhos dos textos...\")\n",
    "print(f\"Total de hinos: {len(hinos_analise)}\")\n",
    "\n",
    "# Testar com um texto específico primeiro\n",
    "print(\"\\nTestando modelo com um texto simples...\")\n",
    "texto_teste = \"Jesus é o meu salvador e eu o amo muito\"\n",
    "resultado_teste = analisar_emocoes(texto_teste)\n",
    "print(f\"Resultado do teste: {list(resultado_teste.keys())[:5]}\")  # Primeiras 5 emoções\n",
    "\n",
    "# Processar apenas uma amostra primeiro para testar\n",
    "print(\"\\nTestando com uma amostra pequena...\")\n",
    "amostra = hinos_analise.head(3).copy()\n",
    "amostra[\"emocoes\"] = amostra[\"texto_limpo\"].apply(analisar_emocoes)\n",
    "\n",
    "print(\"Teste bem-sucedido! Resultado da amostra:\")\n",
    "for idx, row in amostra.iterrows():\n",
    "    emocoes = row[\"emocoes\"]\n",
    "    if emocoes:\n",
    "        top_emocao = max(emocoes.items(), key=lambda x: x[1])\n",
    "        print(f\"{row['nome'][:30]}... -> {top_emocao[0]}: {top_emocao[1]:.3f}\")\n",
    "    else:\n",
    "        print(f\"{row['nome'][:30]}... -> Erro no processamento\")\n",
    "\n",
    "print(f\"\\nPronto! Agora você pode processar todos os {len(hinos_analise)} hinos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a438fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar todos os hinos (pode demorar alguns minutos)\n",
    "print(\"Processando análise de emoções para todos os hinos...\")\n",
    "print(\"Isso pode levar alguns minutos. Progresso:\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Processar em lotes para mostrar progresso\n",
    "batch_size = 50\n",
    "total_batches = len(hinos_analise) // batch_size + 1\n",
    "\n",
    "all_emotions = []\n",
    "for i in range(0, len(hinos_analise), batch_size):\n",
    "    batch = hinos_analise.iloc[i:i+batch_size]\n",
    "    batch_emotions = batch[\"texto_limpo\"].apply(analisar_emocoes)\n",
    "    all_emotions.extend(batch_emotions.tolist())\n",
    "    \n",
    "    current_batch = i // batch_size + 1\n",
    "    print(f\"Lote {current_batch}/{total_batches} concluído ({i+len(batch)}/{len(hinos_analise)} hinos)\")\n",
    "\n",
    "# Adicionar resultados ao dataframe\n",
    "hinos_analise[\"emocoes\"] = all_emotions\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nProcessamento concluído em {end_time - start_time:.1f} segundos!\")\n",
    "print(f\"Total de hinos processados: {len(hinos_analise)}\")\n",
    "\n",
    "# Salvar resultados\n",
    "hinos_analise.to_pickle(\"..\\\\assets\\\\hinos_analise_com_emocoes.pkl\")\n",
    "print(\"Resultados salvos em: ..\\\\assets\\\\hinos_analise_com_emocoes.pkl\")\n",
    "\n",
    "# Mostrar amostra dos resultados\n",
    "print(\"\\nAmostra dos resultados:\")\n",
    "for idx, row in hinos_analise.head(10).iterrows():\n",
    "    emocoes = row[\"emocoes\"]\n",
    "    if emocoes:\n",
    "        top_emocao = max(emocoes.items(), key=lambda x: x[1])\n",
    "        print(f\"{row['nome'][:40]}... -> {top_emocao[0]}: {top_emocao[1]:.3f}\")\n",
    "    else:\n",
    "        print(f\"{row['nome'][:40]}... -> Erro no processamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4508b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise e visualização dos resultados de emoções\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Verificar se os dados foram processados\n",
    "if \"emocoes\" not in hinos_analise.columns:\n",
    "    print(\"Execute a célula anterior primeiro para processar as emoções!\")\n",
    "else:\n",
    "    print(\"Analisando resultados das emoções...\")\n",
    "    \n",
    "    # Extrair a emoção dominante de cada hino\n",
    "    emocoes_dominantes = []\n",
    "    scores_dominantes = []\n",
    "    \n",
    "    for emocoes in hinos_analise[\"emocoes\"]:\n",
    "        if emocoes:\n",
    "            top_emocao = max(emocoes.items(), key=lambda x: x[1])\n",
    "            emocoes_dominantes.append(top_emocao[0])\n",
    "            scores_dominantes.append(top_emocao[1])\n",
    "        else:\n",
    "            emocoes_dominantes.append(\"unknown\")\n",
    "            scores_dominantes.append(0.0)\n",
    "    \n",
    "    hinos_analise[\"emocao_dominante\"] = emocoes_dominantes\n",
    "    hinos_analise[\"score_dominante\"] = scores_dominantes\n",
    "    \n",
    "    # 1. Distribuição das emoções dominantes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    emocao_counts = pd.Series(emocoes_dominantes).value_counts().head(10)\n",
    "    emocao_counts.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Top 10 Emoções Dominantes nos Hinos')\n",
    "    plt.xlabel('Emoção')\n",
    "    plt.ylabel('Quantidade de Hinos')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Distribuição dos scores das emoções dominantes\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(scores_dominantes, bins=20, color='lightcoral', alpha=0.7)\n",
    "    plt.title('Distribuição dos Scores das Emoções Dominantes')\n",
    "    plt.xlabel('Score da Emoção')\n",
    "    plt.ylabel('Frequência')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Estatísticas das emoções\n",
    "    print(\"\\n=== ESTATÍSTICAS DAS EMOÇÕES ===\")\n",
    "    print(f\"Total de hinos analisados: {len(hinos_analise)}\")\n",
    "    print(f\"Hinos com erro no processamento: {emocoes_dominantes.count('unknown')}\")\n",
    "    print(f\"Score médio das emoções dominantes: {np.mean([s for s in scores_dominantes if s > 0]):.3f}\")\n",
    "    \n",
    "    print(\"\\nTop 10 emoções mais frequentes:\")\n",
    "    for i, (emocao, count) in enumerate(emocao_counts.head(10).items(), 1):\n",
    "        percentage = (count / len(hinos_analise)) * 100\n",
    "        print(f\"{i:2d}. {emocao:15s}: {count:3d} hinos ({percentage:4.1f}%)\")\n",
    "    \n",
    "    # 4. Exemplos de hinos por emoção dominante\n",
    "    print(\"\\n=== EXEMPLOS POR EMOÇÃO ===\")\n",
    "    for emocao in emocao_counts.head(5).index:\n",
    "        hinos_emocao = hinos_analise[hinos_analise[\"emocao_dominante\"] == emocao]\n",
    "        exemplo = hinos_emocao.iloc[0]\n",
    "        print(f\"\\n{emocao.upper()} (score: {exemplo['score_dominante']:.3f}):\")\n",
    "        print(f\"  Hino: {exemplo['nome']}\")\n",
    "        print(f\"  Texto: {exemplo['texto_limpo'][:100]}...\")\n",
    "        \n",
    "    print(f\"\\nProcessamento concluído! Dados salvos com análise de emoções.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf714e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização detalhada: Heatmap de emoções por hino\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar se os dados foram processados\n",
    "if \"emocoes\" not in hinos_analise.columns:\n",
    "    print(\"Execute as células anteriores primeiro para processar as emoções!\")\n",
    "else:\n",
    "    print(\"Criando heatmap de emoções...\")\n",
    "    \n",
    "    # Expandir as emoções em colunas numéricas para uma amostra\n",
    "    # (usar todos os hinos seria muito denso para visualizar)\n",
    "    amostra_viz = hinos_analise.head(20).copy()  # Primeiros 20 hinos\n",
    "    \n",
    "    # Criar dataframe com as emoções expandidas\n",
    "    emocoes_expandidas = []\n",
    "    nomes_hinos = []\n",
    "    \n",
    "    for idx, row in amostra_viz.iterrows():\n",
    "        if row[\"emocoes\"]:\n",
    "            emocoes_expandidas.append(row[\"emocoes\"])\n",
    "            nomes_hinos.append(row[\"nome\"][:30] + \"...\")  # Truncar nomes longos\n",
    "        \n",
    "    if emocoes_expandidas:\n",
    "        emo_df = pd.DataFrame(emocoes_expandidas, index=nomes_hinos)\n",
    "        \n",
    "        # Selecionar apenas as emoções mais comuns para visualização\n",
    "        emocoes_principais = emo_df.mean().nlargest(10).index\n",
    "        emo_df_filtrado = emo_df[emocoes_principais]\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(emo_df_filtrado, annot=True, cmap=\"YlOrRd\", fmt=\".2f\", \n",
    "                   cbar_kws={'label': 'Score da Emoção'})\n",
    "        plt.title(\"Distribuição de Emoções por Hino\\n(Amostra dos primeiros 20 hinos)\")\n",
    "        plt.xlabel(\"Emoção\")\n",
    "        plt.ylabel(\"Hino\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Heatmap criado com {len(emo_df_filtrado)} hinos e {len(emocoes_principais)} emoções principais.\")\n",
    "        print(f\"Emoções visualizadas: {list(emocoes_principais)}\")\n",
    "    else:\n",
    "        print(\"Nenhuma emoção foi processada com sucesso. Verifique os dados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d567df",
   "metadata": {},
   "source": [
    "## ✅ Problema Resolvido!\n",
    "\n",
    "### O que estava causando o erro:\n",
    "\n",
    "1. **Parâmetro depreciado**: `return_all_scores=True` foi substituído por `top_k=None`\n",
    "2. **Limite de tokens**: O modelo BERT tem limite de 512 tokens, mas alguns textos dos hinos eram muito longos (até 2250 caracteres)\n",
    "3. **Formato do resultado**: O classificador retorna uma lista de listas, não uma lista simples\n",
    "4. **Falta de tratamento de erro**: Sem proteção para textos problemáticos\n",
    "\n",
    "### Correções aplicadas:\n",
    "\n",
    "1. ✅ **Configuração correta do pipeline**: Substituído `return_all_scores` por `top_k=None`\n",
    "2. ✅ **Truncamento automático**: Adicionado `max_length=512` e `truncation=True`\n",
    "3. ✅ **Função de truncamento**: Criada função específica para lidar com textos longos\n",
    "4. ✅ **Tratamento de erros**: Adicionado try/catch para textos problemáticos\n",
    "5. ✅ **Correção do formato**: Ajustado para lidar com `resultado[0]` (lista de listas)\n",
    "6. ✅ **Processamento em lotes**: Para mostrar progresso durante o processamento\n",
    "7. ✅ **Visualizações melhoradas**: Heatmap e análises estatísticas\n",
    "\n",
    "### Como usar:\n",
    "\n",
    "1. **Execute a primeira célula** para configurar o modelo e testar com amostra\n",
    "2. **Execute a segunda célula** para processar todos os 795 hinos (demora alguns minutos)\n",
    "3. **Execute a terceira célula** para ver análises e estatísticas\n",
    "4. **Execute a quarta célula** para visualizar o heatmap de emoções\n",
    "\n",
    "Os resultados serão salvos em `../assets/hinos_analise_com_emocoes.pkl`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
