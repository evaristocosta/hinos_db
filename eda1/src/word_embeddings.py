import streamlit as st
import pandas as pd
from src.pipeline import hinos_processados, similarity_matrices
import plotly.express as px
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import NMF

#    Word embeddings (eda1_part4):
st.title("üìù Embeddings de Palavras")

"""
Nesta se√ß√£o, exploramos os embeddings de palavras gerados a partir dos textos dos hinos.
Utilizamos t√©cnicas de processamento de linguagem natural para transformar os textos em representa√ß√µes 
vetoriais densas, que capturam o significado sem√¢ntico das palavras. Esses embeddings permitem analisar 
similaridades entre hinos, realizar clustering e identificar t√≥picos comuns.
"""

hinos_analise: pd.DataFrame = hinos_processados()
hinos_analise["word_cluster"] = hinos_analise["word_cluster"].astype("category")
hinos_analise["NMF_topic"] = hinos_analise["NMF_topic"].astype("category")
# hinos_analise = hinos_analise.rename_axis("N¬∫")
similarity_word, _, _ = similarity_matrices()

st.sidebar.header("Filtros")
categorias_unicas = hinos_analise["categoria_abr"].unique()
categorias_selecionadas = st.sidebar.multiselect(
    "Selecione as categorias",
    options=categorias_unicas,
    placeholder="Todas as categorias",
)
if categorias_selecionadas:
    hinos_analise = hinos_analise[
        hinos_analise["categoria_abr"].isin(categorias_selecionadas)
    ]

# - Matrizes de similaridade com heatmap
# estrat√©gia de peso: TF-IDF
"""
## Matriz de Similaridade entre Hinos

Aqui, visualizamos a matriz de similaridade entre os hinos com base nos embeddings de palavras, calculada a partir da 
estrat√©gia de peso TF-IDF. Cada c√©lula na matriz representa o grau de similaridade entre dois hinos, onde valores 
mais altos indicam maior similaridade sem√¢ntica.

"""

st.warning("Aplicar filtros pode causar problemas na visualiza√ß√£o da matriz de similaridade." , icon="‚ö†Ô∏è")

# filtrar a matriz de similaridade para mostrar apenas os hinos presentes em hinos_analise
selected_idx = list(hinos_analise.index)

# se similarity_word for DataFrame, usamos .loc; caso seja ndarray, convertemos para DataFrame com √≠ndices posicionais
if hasattr(similarity_word, "loc"):
    sim_filtered = similarity_word.loc[selected_idx, selected_idx]
else:
    sim_df = pd.DataFrame(
        similarity_word,
        index=range(similarity_word.shape[0]),
        columns=range(similarity_word.shape[0]),
    )
    sim_filtered = sim_df.loc[selected_idx, selected_idx]

fig = px.imshow(
    sim_filtered,
    x=sim_filtered.columns.astype(str),
    y=sim_filtered.index.astype(str),
    labels=dict(x="Hinos", y="Hinos", color="Similaridade"),
    width=600,
    height=600,
    color_continuous_scale="Cividis",
)
st.plotly_chart(fig)

"""
Diferentemente da matriz de similaridade baseada em TF-IDF, que se concentra na frequ√™ncia e import√¢ncia das palavras 
nos documentos, a matriz de similaridade baseada em embeddings de palavras captura rela√ß√µes sem√¢nticas mais profundas 
entre os hinos. Isso significa que hinos com significados semelhantes, mesmo que usem palavras diferentes, podem ser 
identificados como similares, o que explica porque mais hinos aparecem como similares nesta matriz.

Dois hinos que chamam a aten√ß√£o s√£o 106 -- "Pela f√© somos salvos" e 179 -- "Pela f√© eu posso contemplar Jesus": ambos tem 
baixa similaridade com a maioria dos outros hinos, mas alta similaridade entre si. Isso sugere que, apesar de usarem 
palavras diferentes, eles compartilham um significado sem√¢ntico semelhante, relacionado ao tema da f√© e salva√ß√£o.
"""

# - Hinos mais semelhantes
"""
### Hinos mais semelhantes

A seguir, selecione um hino para ver os mais semelhantes com base nos embeddings de palavras.
"""

hinos_opcoes = [
    f"{num} - {row['nome']}" for num, row in hinos_analise.iterrows()
]
hino_selecionado = st.selectbox(
    "Pesquisar hino (n√∫mero ou nome)",
    options=hinos_opcoes,
    placeholder="Digite para buscar...",
    index=None,
    help="Digite o n√∫mero ou parte do nome do hino para pesquisar",
)
if hino_selecionado:
    hymn_num = int(hino_selecionado.split(" - ")[0])
    hymn_name = hinos_analise.loc[hymn_num, "nome"]

    st.metric(label="üéµ Hino", value=f"{hymn_num} ‚Äî {hymn_name}")

    similarities_tfidf = list(enumerate(similarity_word.iloc[hymn_num]))
    similarities_tfidf = sorted(similarities_tfidf, key=lambda x: x[1], reverse=True)

    rows = []
    for idx, score in similarities_tfidf[1:11]:
        rows.append(
            {
                "Hino": int(idx),
                "Nome": hinos_analise["nome"].iloc[idx],
                "Similaridade": float(score),
            }
        )
    df_sim = pd.DataFrame(rows).set_index("Hino")
    st.dataframe(df_sim.style.format({"Similaridade": "{:.3f}"}))
else:
    st.caption("Selecione um hino para ver os mais semelhantes.")

# - Clustering
# Diminui√ß√£o de dimensionalidade: UMAP
# Clustering: K-Means
# Defini√ß√£o de clusters: silhueta - 4¬∫ melhor valor, 10 clusters
"""
## Clustering de Hinos

Utilizando os embeddings de palavras, aplicamos t√©cnicas de redu√ß√£o de dimensionalidade (UMAP) e clustering (K-Means) para 
agrupar os hinos com base em suas similaridades sem√¢nticas. A visualiza√ß√£o abaixo mostra os hinos em um espa√ßo bidimensional,
onde cores diferentes representam clusters (ou grupos) distintos. 

Cada ponto representa um hino, e a proximidade entre os pontos indica similaridade sem√¢ntica. Clusters pr√≥ximos
sugerem temas ou estilos comuns entre os hinos. 

A defini√ß√£o do n√∫mero de clusters foi baseada na an√°lise de silhueta, resultando em 10 clusters que capturam bem as 
varia√ß√µes nos temas dos hinos -- embora o melhor valor de silhueta tenha sido encontrado para 2 clusters, decidi 
manter 10 clusters para uma representa√ß√£o mais granular e pr√≥xima da quantidade de categorias originais que existem
na colet√¢nea.

"""

fig = px.scatter(
    hinos_analise,
    x="word_umap1",
    y="word_umap2",
    color="word_cluster",
    hover_data=["nome"],
    # title="Clustering de Hinos com Embeddings de Palavras",
    labels={"word_umap1": "", "word_umap2": "", "word_cluster": "Cluster"},
    width=600,
    height=600,
)
st.plotly_chart(fig)

"""
O agrupamento resultante permite dividir claramente os hinos em diferentes categorias. No geral, todos os hinos partilham
de um espa√ßo comum. No entanto, alguns clusters se destacam por sua separa√ß√£o mais clara, indicando temas ou estilos √∫nicos.
Por exemplo, os clusters 8 e 6 tem parte no espa√ßo comum, mas tamb√©m possuem √°reas distintas, sugerindo que embora
compartilhem algumas caracter√≠sticas com outros hinos, eles tamb√©m possuem elementos √∫nicos que os diferenciam. 
O cluster 9, por outro lado, est√° totalmente isolado no canto superior direito, indicando que os hinos nesse grupo 
s√£o semanticamente distintos dos demais.

"""

# - Termos mais frequentes por cluster
"""
### Termos mais frequentes por cluster

A seguir, apresentamos os primeiros 8 termos mais frequentes em cada cluster de hinos, conforme identificado pelo 
algoritmo de clustering. Esses termos fornecem insights sobre os temas predominantes em cada grupo de hinos. 
"""


rows = []
for c in sorted(hinos_analise["word_cluster"].unique()):
    cluster_tokens = hinos_analise.loc[
        hinos_analise["word_cluster"] == c, "tokens_no_stops"
    ].sum()
    top_terms = [t for t, _ in Counter(cluster_tokens).most_common(8)]
    cluster_series = hinos_analise.loc[hinos_analise["word_cluster"] == c, "nome"]
    sampled = cluster_series.sample(n=min(3, len(cluster_series)), random_state=42)
    top_hinos = [f"{int(idx)} - {name}" for idx, name in sampled.items()]
    rows.append(
        {
            "Cluster": str(c),
            "Termos": ", ".join(top_terms),
            "Hinos de exemplo": " | ".join(top_hinos),
        }
    )

df_clusters = pd.DataFrame(rows).set_index("Cluster")
st.dataframe(df_clusters)


"""
√â not√°vel que algumas palavras-chave, como "Senhor", "Jesus" e "Deus", aparecem frequentemente em m√∫ltiplos clusters,
indicando sua import√¢ncia central nos temas dos hinos. Como vimos em an√°lises anteriores, essas s√£o as palavras
mais comuns em todo o corpus de hinos.

Interessantemente, os termos relativos ao cluster 9, que est√° isolado no espa√ßo UMAP, n√£o diferem muito dos termos 
dos outros clusters. Isso sugere que, apesar da separa√ß√£o visual, os hinos desse grupo compartilham semelhan√ßas tem√°ticas
com os demais.
"""


hinos_cluster9 = hinos_analise[hinos_analise["word_cluster"] == 9][
    ["nome", "categoria_abr"]
].rename_axis("N¬∫")
f"""
#### Cluster 9 em perspectiva

O cluster 9 √© composto por um total de {hinos_cluster9.shape[0]} hinos. A seguir, s√£o apresentados os hinos 
pertencentes a este cluster, que se destaca por sua separa√ß√£o no espa√ßo UMAP.

"""

st.dataframe(
    hinos_cluster9, column_config={"nome": "Nome do Hino", "categoria_abr": "Categoria"}
)

"""
N√£o h√° uma rela√ß√£o √≥bvia entre os hinos do cluster 9 em termos de categoria, sugerindo que a separa√ß√£o observada no espa√ßo UMAP
pode ser atribu√≠da a outros fatores sem√¢nticos ou estil√≠sticos presentes nos textos dos hinos.
"""


""" 
### Rela√ß√£o entre Clusters e Categorias da Colet√¢nea


Analisamos a distribui√ß√£o dos clusters de hinos em rela√ß√£o √†s categorias originais da colet√¢nea. Isso nos ajuda a entender como os 
agrupamentos baseados em embeddings de palavras correspondem √†s categorias pr√©-definidas. A seguir, apresentamos uma visualiza√ß√£o 
que mostra a propor√ß√£o de hinos de cada categoria dentro de cada cluster.
"""

# tabela de conting√™ncia: categorias x clusters
ct = pd.crosstab(
    hinos_analise["categoria_abr"], hinos_analise["word_cluster"]
).sort_index()

# Heatmap (propor√ß√µes por categoria) com anota√ß√µes dentro dos quadrados
ct_counts = ct.copy()
ct_prop = ct_counts.div(
    ct_counts.sum(axis=1), axis=0
)  # normaliza por categoria (linha)
ct_prop_pct = ct_prop * 100  # em porcentagem

x = ct.index.tolist()  # categorias
y = [str(c) for c in ct.columns]  # clusters (string para r√≥tulos)

fig_ct = px.imshow(
    ct_prop_pct.T.values,
    x=x,
    y=y,
    labels={
        "x": "Categoria da Colet√¢nea",
        "y": "Cluster",
        "color": "Propor√ß√£o (%)",
    },
    color_continuous_scale="Cividis",
    width=800,
    height=420,
)

# adicionar anota√ß√µes com porcentagem e contagem
z = ct_prop_pct.T.values
counts = ct_counts.T.values
z_max = z.max() if z.size else 0
for i_y, y_label in enumerate(y):
    for i_x, x_label in enumerate(x):
        val_pct = z[i_y, i_x]
        cnt = int(counts[i_y, i_x])
        text = f"{val_pct:.1f}%\n({cnt})"
        # escolha de cor do texto para legibilidade
        text_color = "white" if val_pct > (z_max / 2 if z_max > 0 else 0.5) else "black"
        fig_ct.add_annotation(
            x=x_label,
            y=y_label,
            text=text,
            showarrow=False,
            font=dict(color=text_color, size=11),
            xanchor="center",
            yanchor="middle",
        )

fig_ct.update_layout(margin=dict(l=40, r=40, t=40, b=40))
st.plotly_chart(fig_ct)


"""
Podemos observar que alguns clusters t√™m alguma associa√ß√£o com categorias espec√≠ficas da colet√¢nea. Por exemplo, o cluster 1 tem uma forte presen√ßa 
de hinos da categoria "CLAMOR", enquanto o cluster 4 √© dominado por hinos da categoria "SALMOS DE LOUVOR". No entanto, muitos clusters apresentam 
uma distribui√ß√£o mais diversificada de categorias, indicando que os agrupamentos baseados em embeddings de palavras n√£o correspondem diretamente √†s 
categorias pr√©-definidas. Isso sugere que os embeddings capturam nuances sem√¢nticas que transcendem as categorias tradicionais, refletindo a 
complexidade dos temas abordados nos hinos.
"""


# - T√≥picos comuns
"""
## T√≥picos comuns entre os hinos

Utilizando a t√©cnica de Non-negative Matrix Factorization (NMF) aplicada √† representa√ß√£o TF-IDF dos textos dos hinos,
identificamos t√≥picos comuns presentes nos hinos. Usamos o n√∫mero de clusters previamente definido como o n√∫mero de 
t√≥picos para garantir consist√™ncia na an√°lise.
A seguir, apresentamos os principais t√≥picos e suas palavras-chave associadas.
"""


n_topics = hinos_analise["word_cluster"].nunique()

# Criar TF-IDF apenas para an√°lise de t√≥picos
vectorizer = TfidfVectorizer(
    max_features=500,
    stop_words=None,  # voc√™ j√° removeu as stopwords
    ngram_range=(1, 3),  # uni, bi e trigramas
    min_df=2,  # palavra deve aparecer em pelo menos 2 documentos
)

# Usar texto j√° limpo (sem stopwords)
texts_for_topics = [" ".join(tokens) for tokens in hinos_analise["tokens_no_stops"]]
X_tfidf = vectorizer.fit_transform(texts_for_topics)

# NMF tamb√©m funciona com TF-IDF
nmf = NMF(n_components=n_topics, random_state=42, max_iter=100)
nmf_topics = nmf.fit_transform(X_tfidf)


def display_topics(model, feature_names, n_top_words=10):
    rows = []
    for idx, topic in enumerate(model.components_):
        top_words = [feature_names[i] for i in topic.argsort()[: -n_top_words - 1 : -1]]
        rows.append({"T√≥pico": f"{idx+1}", "Palavras-chave": ", ".join(top_words)})
    df_topics = pd.DataFrame(rows).set_index("T√≥pico")
    return df_topics


feature_names = vectorizer.get_feature_names_out()
df_topics = display_topics(nmf, feature_names)
st.dataframe(df_topics)

"""
Diferentemente dos termos mais frequentes por cluster, os t√≥picos identificados pelo NMF consideram tamb√©m bigramas e trigramas,
o que pode revelar temas mais espec√≠ficos e contextuais presentes nos hinos. Por exemplo, o t√≥pico 3 est√° diretamente
relacionado ao tema de "Volta de Jesus", enquanto que os t√≥picos 5 e 9 s√£o de "Gl√≥ria" e "Aleluia", respectivamente.
Ainda, o t√≥pico 6 cont√©m termos relacionados ao clamor pelo sangue de Jesus, e o t√≥pico 10 indica hinos de servi√ßo e adora√ß√£o.
"""

# - Distribui√ß√£o de t√≥picos
"""
### Distribui√ß√£o de T√≥picos nos Hinos

Podemos usar os t√≥picos identificados para analisar a distribui√ß√£o dos hinos no espa√ßo UMAP, colorindo-os de acordo com o t√≥pico
dominante atribu√≠do pelo NMF.
"""

fig = px.scatter(
    hinos_analise,
    x="word_umap1",
    y="word_umap2",
    labels={"word_umap1": "", "word_umap2": "", "NMF_topic": "T√≥pico NMF"},
    color="NMF_topic",
    hover_data=["nome"],
    width=600,
    height=600,
)
st.plotly_chart(fig)

"""
Diferente dos claros agrupamentos observados com o clustering baseado em K-Means, a distribui√ß√£o dos t√≥picos NMF no espa√ßo UMAP
√© mais difusa. Isso sugere que os t√≥picos identificados pelo NMF capturam nuances sem√¢nticas que n√£o se traduzem 
diretamente em clusters distintos, indicando uma sobreposi√ß√£o maior entre os temas dos hinos.

√â poss√≠vel observar algumas rela√ß√µes, no entanto. Por exemplo, os hinos do t√≥pico 2 aparecem na mesma regi√£o do espa√ßo UMAP
associada ao cluster 6, e o t√≥pico 7 est√° presente em uma √°rea pr√≥xima ao cluster 5. Mas o que chama mais aten√ß√£o, √© que o
t√≥pico 4 est√° fortemente concentrado na regi√£o do cluster 9, sugerindo que os hinos desse t√≥pico compartilham caracter√≠sticas
sem√¢nticas distintas dos demais, e similares entre si.
"""

hinos_topico4 = hinos_analise[hinos_analise["NMF_topic"] == 4][
    ["nome", "categoria_abr"]
].rename_axis("N¬∫")

f"""
#### Hinos do T√≥pico 4

O t√≥pico 4 √© composto por um total de {hinos_topico4.shape[0]} hinos, mais do que o cluster 9 (que tem 
{hinos_cluster9.shape[0]} hinos). A seguir, apresentamos os hinos pertencentes ao t√≥pico 4.
"""

st.dataframe(
    hinos_topico4, column_config={"nome": "Nome do Hino", "categoria_abr": "Categoria"}
)

# termos do cluster 9: gl√≥ria, jesus, aleluia, sempre, senhor, deus, grande, vencendo
# t√≥pico 4: senhor, louvor, senhor senhor, voz, senhor deus, terra, nome, miseric√≥rdia, alma, diante
"""
Observa-se que os hinos do t√≥pico 4 abrangem diversas categorias, sendo que as mais marcantes s√£o sobre volta de Jesus
e louvor. Me chamou a aten√ß√£o o termo "vencendo" do cluster 9, e "terra" do t√≥pico 4, como distintivos entre os demais grupos e 
t√≥picos. Talvez esses termos expliquem a separa√ß√£o observada no espa√ßo UMAP do cluster 9: hinos que enfatizam
a vit√≥ria de Jesus e a abrang√™ncia de Seu reino na terra.
"""
