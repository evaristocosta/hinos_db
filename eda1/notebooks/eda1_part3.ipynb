{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609abdba",
   "metadata": {},
   "source": [
    "# Part 3 - texto\n",
    "\n",
    "- maior/menor louvor\n",
    "- word length (maybe)\n",
    "- bag-of-words with frequency\n",
    "- gensim corpus\n",
    "- tf-idf\n",
    "- named entity recognition (spacy or polyglot)\n",
    "- next: category classification for avulsos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d72b2",
   "metadata": {},
   "source": [
    "## Maior e menor louvor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811adb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "assets_folder = Path(\"../assets\")\n",
    "hinos_analise = pd.read_pickle(assets_folder / \"hinos_analise.pkl\")\n",
    "hinos_analise = hinos_analise.set_index(\"numero\")\n",
    "hinos_analise[\"categoria_abr\"] = hinos_analise[\"categoria\"].apply(\n",
    "    lambda x: x[:13] + \"...\" if len(x) > 15 else x\n",
    ")\n",
    "hinos_analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "stopwords.extend([\"ó\", \"ti\", \"pra\", \"lo\", \"oh\"])\n",
    "text = []\n",
    "text_no_stops = []\n",
    "\n",
    "for hino in tqdm(hinos_analise.to_dict(\"records\")):\n",
    "    tokens = nltk.tokenize.regexp_tokenize(hino[\"texto_limpo\"], r\"\\w+\")\n",
    "    # Replace \"MINH\" with \"MINHA\" with regex\n",
    "    tokens = [nltk.re.sub(r\"^MINH$\", \"MINHA\", palavra) for palavra in tokens]\n",
    "    tokens = [\n",
    "        palavra for palavra in tokens if palavra != \"CORO\" and palavra != \"INSTRUMENTOS\"\n",
    "    ]\n",
    "    tokens_no_stops = [\n",
    "        palavra for palavra in tokens if palavra.lower() not in stopwords\n",
    "    ]\n",
    "    text.append(tokens)\n",
    "    text_no_stops.append(tokens_no_stops)\n",
    "\n",
    "hinos_analise[\"tokens\"] = text\n",
    "hinos_analise[\"tokens_no_stops\"] = text_no_stops\n",
    "# considerando numero total de palavras, pois todas elas tem que ser cantadas, logo impactam no tamanho prático do hino\n",
    "hinos_analise[\"num_tokens\"] = hinos_analise[\"tokens\"].apply(len)\n",
    "hinos_analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(hinos_analise.sort_values(\"num_tokens\", ascending=False))\n",
    "display(hinos_analise.sort_values(\"num_tokens\", ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755eb4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure 'categoria_id' is treated as a categorical variable\n",
    "hinos_analise[\"categoria_id\"] = hinos_analise[\"categoria_id\"].astype(\"category\")\n",
    "\n",
    "# Create a mapping between categoria_id and categoria\n",
    "categoria_mapping = (\n",
    "    hinos_analise[[\"categoria_id\", \"categoria_abr\"]]\n",
    "    .drop_duplicates()\n",
    "    .set_index(\"categoria_id\")[\"categoria_abr\"]\n",
    ")\n",
    "\n",
    "# Create a violin plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\"\"\" sns.violinplot(\n",
    "    data=hinos_analise,\n",
    "    x=\"categoria_id\",\n",
    "    y=\"num_tokens\",\n",
    "    palette=\"viridis\",\n",
    "    inner=\"quartile\",\n",
    ") \"\"\"\n",
    "sns.boxplot(data=hinos_analise, x=\"categoria_id\", y=\"num_tokens\", palette=\"viridis\")\n",
    "\n",
    "# Replace x-ticks with corresponding 'categoria' names\n",
    "plt.xticks(\n",
    "    ticks=range(len(categoria_mapping)),\n",
    "    labels=categoria_mapping,\n",
    "    rotation=90,\n",
    "    ha=\"right\",\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Categoria\")\n",
    "plt.ylabel(\"Number of Tokens\")\n",
    "plt.title(\"Relationship Between Number of Tokens and Categoria (Violin Plot)\")\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418aef02",
   "metadata": {},
   "source": [
    "## Word length (maybe)\n",
    "\n",
    "- bag-of-words with frequency + word map\n",
    "- gensim corpus\n",
    "- tf-idf\n",
    "- named entity recognition (spacy or polyglot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c228acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_lines = hinos_analise.iloc[0][\"tokens_no_stops\"]\n",
    "tokenized_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a frequency list of lengths: line_num_words\n",
    "line_num_words = [len(t_line) for t_line in hinos_analise[\"tokens_no_stops\"].explode().tolist()]\n",
    "\n",
    "# Plot a histogram of the line lengths\n",
    "plt.hist(line_num_words)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f0ae9",
   "metadata": {},
   "source": [
    "## Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14540bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = hinos_analise[\"tokens_no_stops\"].explode().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211aa20e",
   "metadata": {},
   "source": [
    "### Palavras mais longas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2a28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 10 largest words\n",
    "palavras_unique = list(set(palavras))\n",
    "palavras_unique.sort(key=len, reverse=True)\n",
    "print(len(palavras_unique))\n",
    "pd.DataFrame({\n",
    "    \"palavra\": palavras_unique[:10],\n",
    "    \"tamanho\": [len(palavra) for palavra in palavras_unique[:10]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb73d61b",
   "metadata": {},
   "source": [
    "### Bag-of-words with frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(palavras))\n",
    "set_words_full = list(set(palavras))\n",
    "count_words = [palavras.count(i) for i in set_words_full]\n",
    "\n",
    "contagem_palav = pd.DataFrame(\n",
    "    zip(set_words_full, count_words), columns=[\"palavra\", \"contagem\"]\n",
    ")\n",
    "contagem_palav = contagem_palav.sort_values(\"contagem\", ascending=False)\n",
    "contagem_palav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a percentage column\n",
    "contagem_palav[\"percentual\"] = contagem_palav[\"contagem\"] / len(palavras) * 100\n",
    "contagem_palav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba23669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dictionary from the word frequency data\n",
    "word_freq_dict = dict(zip(contagem_palav['palavra'], contagem_palav['contagem']))\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800, \n",
    "    height=400, \n",
    "    background_color='white',\n",
    "    max_words=100,\n",
    "    colormap='viridis',\n",
    "    relative_scaling=0.5,\n",
    "    random_state=42\n",
    ").generate_from_frequencies(word_freq_dict)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - Palavras mais frequentes nos hinos', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also show top 20 most frequent words as a bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_20 = contagem_palav.head(20)\n",
    "plt.barh(range(len(top_20)), top_20['contagem'], color='skyblue')\n",
    "plt.yticks(range(len(top_20)), top_20['palavra'])\n",
    "plt.xlabel('Frequência')\n",
    "plt.title('Top 20 Palavras Mais Frequentes')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f2f13",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "Tentei:\n",
    "- Gensim corpus (problemas de compatibilidade)\n",
    "- NLTK NER (ruim)\n",
    "- Polyglot (não consegui instalar)\n",
    "- SpaCy (péssimos resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_completo = \" \".join(hinos_analise[\"texto_limpo\"])\n",
    "texto_completo[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# python -m spacy download pt_core_news_lg\n",
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "doc = nlp(texto_completo)\n",
    "doc.ents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents[:25]:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
