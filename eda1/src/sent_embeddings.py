import streamlit as st
import pandas as pd
from pipeline import hinos_processados, similarity_matrices
import plotly.express as px
import plotly.graph_objects as go
from collections import Counter
import numpy as np

#    Sequence embeddings (eda1_part5):
st.title("Embeddings de frases üóíÔ∏è")
"""
Nesta se√ß√£o, exploramos os embeddings de frases gerados a partir dos hinos. Os embeddings s√£o representa√ß√µes 
vetoriais que capturam o significado sem√¢ntico de frases inteiras ao inv√©s de palavras isoladas, permitindo 
compara√ß√µes e an√°lises mais profundas.
"""

hinos_analise: pd.DataFrame = hinos_processados()
hinos_analise["sent_cluster"] = hinos_analise["sent_cluster"].astype("category")
hinos_analise["BERT_topic"] = hinos_analise["BERT_topic"].astype("category")
_, similarity_sentence = similarity_matrices()

st.sidebar.header("Filtros")
categorias_unicas = hinos_analise["categoria_abr"].unique()
categorias_selecionadas = st.sidebar.multiselect(
    "Selecione as categorias",
    options=categorias_unicas,
    placeholder="Todas as categorias",
)
if categorias_selecionadas:
    hinos_analise = hinos_analise[
        hinos_analise["categoria_abr"].isin(categorias_selecionadas)
    ]


# modelo = SentenceTransformer("rufimelo/Legal-BERTimbau-sts-base")  # portugu√™s brasileiro
# similaridade = cosine_similarity

"""
# Matriz de Similaridade entre Hinos

Como na an√°lise de embeddings de palavras, aqui apresentamos a matriz de similaridade entre os hinos,
mas agora utilizando os embeddings de frases. 

Para gerar os embeddings de frases, utilizamos o modelo "[rufimelo/Legal-BERTimbau-sts-base](https://huggingface.co/rufimelo/Legal-BERTimbau-sts-base)", 
que √© baseado na arquitetura BERT e foi ajustado para tarefas de similaridade sem√¢ntica em portugu√™s brasileiro.
A similaridade por sua vez, √© calculada usando a similaridade do cosseno.

"""

fig = px.imshow(
    similarity_sentence,
    labels=dict(x="Hinos", y="Hinos", color="Similaridade"),
    width=600,
    height=600,
    color_continuous_scale="Viridis",
)
st.plotly_chart(fig)

"""
Comparando com a matriz de similaridade baseada em embeddings de palavras, podemos observar que a matriz
de embeddings de frases tende a apresentar valores de similaridade mais altos entre os hinos. Isso ocorre porque os 
embeddings de frases capturam o contexto completo das frases, levando em considera√ß√£o a estrutura e o significado 
global, enquanto os embeddings de palavras focam em palavras individuais.
Essa caracter√≠stica dos embeddings de frases permite identificar similaridades sem√¢nticas mais profundas entre os 
hinos, mesmo quando eles utilizam palavras diferentes para expressar ideias semelhantes.

O que chama aten√ß√£o, pela an√°lise visual da matriz, s√£o algumas linhas e colunas mais claras, indicando hinos que
n√£o compartilham muita similaridade com os demais, como o hino 396 - "Abba Pai", ou 13 - "Vamos lavar as vestes". 
Esses hinos podem ser considerados mais √∫nicos em termos de conte√∫do e estilo, destacando-se na cole√ß√£o.
A regi√£o dos corinhos (maiores que 731) tamb√©m se destaca, mostrando hinos de menor similaridade com os demais, e
mesmo entre eles. De fato, s√£o hinos caracter√≠sticos, com estruturas e temas pr√≥prios, o que justifica sua menor 
similaridade. O mesmo acontece com alguns hinos de clamor, e de invoca√ß√£o. No entanto, a faixa que mais chama aten√ß√£o
√© o intervalo entre os hinos 396 e 403, que apresentam uma similaridade muito baixa com o restante dos hinos. Um
fator que pode ser determinante, √© que esses hinos s√£o mais curtos, com menos versos, o que pode influenciar
na gera√ß√£o dos embeddings e na similaridade calculada.
"""


"""
## Rela√ß√£o de tamanho do hino e similaridade

Aqui, investigamos se existe alguma correla√ß√£o entre o tamanho dos hinos (medido pelo n√∫mero de tokens)
e a similaridade m√©dia com os demais hinos, utilizando os embeddings de frases.
"""


# restringe a matriz de similaridade aos hinos atualmente no dataframe (caso haja filtro)
idx = hinos_analise.index.tolist()
sim_sub = similarity_sentence.loc[idx, idx]

# m√©dia de similaridade com os demais (exclui a diagonal / self-similarity)
n = sim_sub.shape[0]
if n > 1:
    mean_sim = (sim_sub.sum(axis=1) - np.diag(sim_sub).astype(float)) / (n - 1)
else:
    mean_sim = pd.Series(0.0, index=sim_sub.index)


# conta n√∫mero de tokens (compat√≠vel com listas ou strings)
def _count_tokens(x):
    try:
        return len(x)
    except Exception:
        if pd.isna(x):
            return 0
        return len(str(x).split())


size_series = hinos_analise["tokens_no_stops"].apply(_count_tokens)

plot_df = pd.DataFrame(
    {
        "hino": hinos_analise.index,
        "nome": hinos_analise["nome"],
        "tamanho": size_series,
        "similaridade_media": mean_sim.loc[hinos_analise.index].astype(float),
    }
).reset_index(drop=True)

# calcula correla√ß√£o e ajuste linear
mask = np.isfinite(plot_df["tamanho"]) & np.isfinite(plot_df["similaridade_media"])
corr = np.corrcoef(
    plot_df.loc[mask, "tamanho"], plot_df.loc[mask, "similaridade_media"]
)[0, 1]
# reg_slope, reg_intercept = np.polyfit(
#     plot_df.loc[mask, "tamanho"], plot_df.loc[mask, "similaridade_media"], 1
# )

# scatter + linha de regress√£o
fig = px.scatter(
    plot_df,
    x="tamanho",
    y="similaridade_media",
    hover_data=["hino", "nome"],
    labels={
        "tamanho": "N√∫mero de tokens (tamanho do hino)",
        "similaridade_media": "Similaridade m√©dia",
    },
    title="Rela√ß√£o entre tamanho do hino e similaridade m√©dia",
    width=700,
    height=450,
)

# x_line = np.linspace(plot_df["tamanho"].min(), plot_df["tamanho"].max(), 100)
# y_line = reg_slope * x_line + reg_intercept
# fig.add_trace(
#     go.Scatter(
#         x=x_line,
#         y=y_line,
#         mode="lines",
#         name="Regress√£o linear",
#         line=dict(color="red"),
#     )
# )

st.plotly_chart(fig)


f"""
Fica claro que a afirma√ß√£o anterior sobre hinos mais curtos terem menor similaridade se confirma aqui. Embora existam hinos
com baixo n√∫mero de tokens que apresentam similaridade m√©dia alta, a tend√™ncia geral indica que hinos mais curtos tendem a ter
menor similaridade m√©dia com os demais hinos. Isso pode ser atribu√≠do ao fato de que hinos mais curtos possuem menos conte√∫do
sem√¢ntico para capturar, o que pode resultar em embeddings menos informativos e, consequentemente, em menor similaridade 
com outros hinos.

A **Correla√ß√£o (Pearson)** entre tamanho e similaridade m√©dia √© igual a {corr:.3f}.
Isso indica uma correla√ß√£o positiva moderada, sugerindo que, em geral, hinos maiores tendem a ter similaridade m√©dia mais alta
com os demais hinos, embora existam exce√ß√µes individuais.
"""


# mostra amostra dos valores
# st.dataframe(plot_df.sort_values("tamanho").head(10).set_index("hino"))


"""
## Hinos mais semelhantes

Usando os dados de similaridade, a seguir voc√™ pode selecionar um hino para ver os mais semelhantes com base 
nos embeddings de senten√ßas.
"""

col1, col2 = st.columns(2)
with col1:
    hymn_num = st.number_input(
        "Selecione o n√∫mero do hino:",
        min_value=int(hinos_analise.index.min()),
        max_value=int(hinos_analise.index.max()),
        value=495,  # um bom exemplo pra iniciar
    )

similarities = list(enumerate(similarity_sentence.iloc[hymn_num]))
similarities = sorted(similarities, key=lambda x: x[1], reverse=True)

with col2:
    st.markdown(f"**üéµ Hino {hymn_num} - {hinos_analise['nome'].iloc[hymn_num]}**")

results = [
    (idx, hinos_analise["nome"].iloc[idx], score) for idx, score in similarities[1:11]
]
df_sim = (
    pd.DataFrame(results, columns=["hino", "nome", "similaridade"])
    .set_index("hino")
    .rename_axis("N¬∫")
)
df_sim["similaridade"] = df_sim["similaridade"].round(3)
st.dataframe(
    df_sim,
    column_config={"nome": "Nome", "similaridade": "Similaridade"},
)


"""
# Clustering de Hinos com Embeddings de Senten√ßas

Assim como na an√°lise de embeddings de palavras, aplicamos t√©cnicas de redu√ß√£o de dimensionalidade (UMAP)
e clustering (K-Means) para visualizar e agrupar os hinos com base em seus embeddings de frases. Levando em conta
resultados da an√°lise de silhueta, optamos por 9 clusters para os embeddings de frases.
"""

fig = px.scatter(
    hinos_analise,
    x="sent_umap1",
    y="sent_umap2",
    color="sent_cluster",
    hover_data=["nome"],
    # title="Clustering de Hinos com Embeddings de Senten√ßas",
    labels={"sent_umap1": "", "sent_umap2": "", "sent_cluster": "Cluster"},
    width=600,
    height=600,
)
st.plotly_chart(fig)

"""
Na an√°lise anterior, pod√≠amos observar alguns hinos bem isolados em termos de similaridade. Aqui, vemos um agrupamento
mais coeso, com menos pontos isolados. Isso sugere que os embeddings de frases capturam melhor as semelhan√ßas sem√¢nticas 
entre os hinos, permitindo uma forma√ß√£o de clusters mais definida.
"""


"""
## Termos mais frequentes por cluster

"""


rows = []
for c in sorted(hinos_analise["sent_cluster"].unique()):
    cluster_tokens = hinos_analise.loc[
        hinos_analise["sent_cluster"] == c, "tokens_no_stops"
    ].sum()
    top_terms = [t for t, _ in Counter(cluster_tokens).most_common(8)]
    cluster_series = hinos_analise.loc[hinos_analise["sent_cluster"] == c, "nome"]
    sampled = cluster_series.sample(n=min(3, cluster_series.shape[0]))
    top_hymns = [f"{idx} - {name}" for idx, name in sampled.items()]
    rows.append(
        {
            "Cluster": c,
            "Top termos": ", ".join(top_terms),
            "Top hinos": " | ".join(top_hymns),
        }
    )

df_terms = pd.DataFrame(rows).set_index("Cluster")
st.dataframe(df_terms)


# ## Rela√ß√£o entre Clusters e Categorias da Colet√¢nea
st.subheader("Rela√ß√£o entre Clusters e Categorias da Colet√¢nea")

# tabela de conting√™ncia: categorias x clusters
ct = pd.crosstab(
    hinos_analise["categoria_abr"], hinos_analise["sent_cluster"]
).sort_index()

# Heatmap (propor√ß√µes por categoria) com anota√ß√µes dentro dos quadrados
ct_counts = ct.copy()
ct_prop = ct_counts.div(
    ct_counts.sum(axis=1), axis=0
)  # normaliza por categoria (linha)
ct_prop_pct = ct_prop * 100  # em porcentagem

x = ct.index.tolist()  # categorias
y = [str(c) for c in ct.columns]  # clusters (string para r√≥tulos)

fig_ct = px.imshow(
    ct_prop_pct.T.values,
    x=x,
    y=y,
    labels={
        "x": "Categoria da Colet√¢nea",
        "y": "Cluster (sent_cluster)",
        "color": "Propor√ß√£o (%)",
    },
    color_continuous_scale="Viridis",
    width=800,
    height=420,
)

# adicionar anota√ß√µes com porcentagem e contagem
z = ct_prop_pct.T.values
counts = ct_counts.T.values
z_max = z.max() if z.size else 0
for i_y, y_label in enumerate(y):
    for i_x, x_label in enumerate(x):
        val_pct = z[i_y, i_x]
        cnt = int(counts[i_y, i_x])
        text = f"{val_pct:.1f}%\n({cnt})"
        # escolha de cor do texto para legibilidade
        text_color = "white" if val_pct > (z_max / 2 if z_max > 0 else 0.5) else "black"
        fig_ct.add_annotation(
            x=x_label,
            y=y_label,
            text=text,
            showarrow=False,
            font=dict(color=text_color, size=11),
            xanchor="center",
            yanchor="middle",
        )

fig_ct.update_layout(margin=dict(l=40, r=40, t=40, b=40))
st.plotly_chart(fig_ct)

# Stacked bar (propor√ß√£o por categoria) ‚Äî mostra composi√ß√£o de clusters dentro de cada categoria
# index_name = ct.index.name or "categoria_abr"
# ct_pct = (
#     ct.div(ct.sum(axis=1), axis=0)
#     .reset_index()
#     .melt(id_vars=index_name, var_name="Cluster", value_name="Propor√ß√£o")
# )
# fig_bar = px.bar(
#     ct_pct,
#     x=index_name,
#     y="Propor√ß√£o",
#     color="Cluster",
#     barmode="stack",
#     labels={
#         index_name: "Categoria da Colet√¢nea",
#         "Propor√ß√£o": "Propor√ß√£o por Categoria",
#     },
#     width=800,
#     height=420,
# )
# fig_bar.update_layout(xaxis={"categoryorder": "array", "categoryarray": ct.index})
# st.plotly_chart(fig_bar)

# # Mostrar tabelas auxiliares (contagens e propor√ß√µes)
# st.markdown("Contagens (Categoria √ó Cluster)")
# st.dataframe(ct)

# st.markdown("Propor√ß√µes por Categoria (normalizado por categoria)")
# st.dataframe(ct.div(ct.sum(axis=1), axis=0).round(3))


"""
# T√≥picos comuns entre os hinos

"""

topics = {
    0: ["me", "meu", "senhor", "ti", "minha", "eu", "mim", "jesus", "√©s", "de"],
    1: ["eu", "que", "me", "meu", "ti", "n√£o", "te", "tudo", "de", "senhor"],
    2: ["eu", "em", "me", "meu", "seu", "jesus", "amor", "com", "que", "deus"],
    3: ["deus", "se", "n√£o", "te", "ele", "que", "em", "teu", "tu", "tua"],
    4: ["amor", "cruz", "por", "me", "jesus", "que", "mim", "eu", "meu", "foi"],
    5: ["nos", "nosso", "teu", "em", "que", "louvor", "vidas", "n√≥s", "nossas", "te"],
    6: ["que", "de", "os", "se", "as", "do", "meu", "deus", "vem", "com"],
    7: ["senhor", "nos", "teu", "santo", "toda", "tua", "sobre", "gl√≥ria", "de", "vem"],
    8: ["aleluia", "gl√≥ria", "de", "c√©u", "oh", "jesus", "rei", "do", "da", "no"],
    9: ["me", "fala", "quero", "te", "em", "tua", "meu", "ardendo", "senhor", "teu"],
    10: [
        "areia",
        "tantos",
        "como",
        "praia",
        "maranata",
        "voltar√°",
        "rei",
        "que",
        "de",
        "viva",
    ],
}

rows = [
    {"T√≥pico": f"T√≥pico {k}", "Top termos": ", ".join(v)}
    for k, v in sorted(topics.items())
]
df_topics = pd.DataFrame(rows).set_index("T√≥pico")

st.table(df_topics)


# - Distribui√ß√£o de t√≥picos
"""
# Distribui√ß√£o de T√≥picos nos Hinos

"""

fig = px.scatter(
    hinos_analise,
    x="sent_umap1",
    y="sent_umap2",
    color="BERT_topic",
    hover_data=["nome"],
    labels={"sent_umap1": "", "sent_umap2": "", "BERT_topic": "T√≥pico BERT"},
    width=600,
    height=600,
)
st.plotly_chart(fig)
