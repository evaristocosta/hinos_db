import streamlit as st
import pandas as pd
from src.pipeline import hinos_processados, similarity_matrices
import plotly.express as px
import plotly.graph_objects as go
from collections import Counter
import numpy as np

#    Sequence embeddings (eda1_part5):
st.title("üóíÔ∏è Embeddings de frases")
"""
Nesta se√ß√£o, exploramos os embeddings de frases gerados a partir dos hinos. Os embeddings s√£o representa√ß√µes 
vetoriais que capturam o significado sem√¢ntico de frases inteiras ao inv√©s de palavras isoladas, permitindo 
compara√ß√µes e an√°lises mais profundas.
"""

hinos_analise: pd.DataFrame = hinos_processados()
hinos_analise["sent_cluster"] = hinos_analise["sent_cluster"].astype("category")
hinos_analise["BERT_topic"] = hinos_analise["BERT_topic"].astype("category")
_, similarity_sentence, _ = similarity_matrices()

st.sidebar.header("Filtros")
categorias_unicas = hinos_analise["categoria_abr"].unique()
categorias_selecionadas = st.sidebar.multiselect(
    "Selecione as categorias",
    options=categorias_unicas,
    placeholder="Todas as categorias",
)
if categorias_selecionadas:
    hinos_analise = hinos_analise[
        hinos_analise["categoria_abr"].isin(categorias_selecionadas)
    ]


# modelo = SentenceTransformer("rufimelo/Legal-BERTimbau-sts-base")  # portugu√™s brasileiro
# similaridade = cosine_similarity

"""
## Matriz de Similaridade entre Hinos

Como na an√°lise de embeddings de palavras, aqui apresentamos a matriz de similaridade entre os hinos,
mas agora utilizando os embeddings de frases. 

Para gerar os embeddings de frases, utilizamos o modelo "[rufimelo/Legal-BERTimbau-sts-base](https://huggingface.co/rufimelo/Legal-BERTimbau-sts-base)", 
que √© baseado na arquitetura BERT e foi ajustado para tarefas de similaridade sem√¢ntica em portugu√™s brasileiro.
A similaridade por sua vez, √© calculada usando a similaridade do cosseno.

Um ponto importante √© que os embeddings de frases s√£o gerados a partir do texto completo de cada hino,
e n√£o apenas de palavras individuais -- processo de tokeniza√ß√£o e remo√ß√£o de stopwords n√£o s√£o aplicados aqui.

"""

st.warning("Aplicar filtros pode causar problemas na visualiza√ß√£o da matriz de similaridade." , icon="‚ö†Ô∏è")

# restringe a matriz de similaridade aos hinos atualmente no dataframe (caso haja filtro)
idx = hinos_analise.index.tolist()
sim_sub = similarity_sentence.loc[idx, idx]

fig = px.imshow(
    sim_sub,
    labels=dict(x="Hinos", y="Hinos", color="Similaridade"),
    x=sim_sub.columns,
    y=sim_sub.index,
    width=600,
    height=600,
    color_continuous_scale="Cividis",
)
st.plotly_chart(fig)

"""
Comparando com a matriz de similaridade baseada em embeddings de palavras, podemos observar que a matriz
de embeddings de frases tende a apresentar valores de similaridade mais altos entre os hinos. Isso ocorre porque os 
embeddings de frases capturam o contexto completo das frases, levando em considera√ß√£o a estrutura e o significado 
global, enquanto os embeddings de palavras focam em palavras individuais.
Essa caracter√≠stica dos embeddings de frases permite identificar similaridades sem√¢nticas mais profundas entre os 
hinos, mesmo quando eles utilizam palavras diferentes para expressar ideias semelhantes.

O que chama aten√ß√£o, pela an√°lise visual da matriz, s√£o algumas linhas e colunas mais "azuis", indicando hinos que
n√£o compartilham muita similaridade com os demais, como o hino 396 -- "Abba Pai", ou 13 -- "Vamos lavar as vestes". 
Esses hinos podem ser considerados mais √∫nicos em termos de conte√∫do e estilo, destacando-se na colet√¢nea.
A regi√£o dos corinhos (maiores que 731) tamb√©m se destaca, mostrando hinos de menor similaridade com os demais, e
mesmo entre eles. De fato, s√£o hinos caracter√≠sticos, com estruturas e temas pr√≥prios, o que justifica sua menor 
similaridade. O mesmo acontece com alguns hinos de clamor, e de invoca√ß√£o. No entanto, a faixa que mais chama aten√ß√£o
√© o intervalo entre os hinos 396 e 403, que apresentam uma similaridade muito baixa com o restante dos hinos. Um
fator que pode ser determinante, √© que esses hinos s√£o mais curtos, com menos versos, o que pode influenciar
na gera√ß√£o dos embeddings e na similaridade calculada.
"""


"""
### Rela√ß√£o de tamanho do hino e similaridade

Aqui, investigamos se existe alguma correla√ß√£o entre o tamanho dos hinos (medido pelo n√∫mero de tokens)
e a similaridade m√©dia com os demais hinos, utilizando os embeddings de frases.
"""


# restringe a matriz de similaridade aos hinos atualmente no dataframe (caso haja filtro)
idx = hinos_analise.index.tolist()
sim_sub = similarity_sentence.loc[idx, idx]

# m√©dia de similaridade com os demais (exclui a diagonal / self-similarity)
n = sim_sub.shape[0]
if n > 1:
    mean_sim = (sim_sub.sum(axis=1) - np.diag(sim_sub).astype(float)) / (n - 1)
else:
    mean_sim = pd.Series(0.0, index=sim_sub.index)


# conta n√∫mero de tokens (compat√≠vel com listas ou strings)
def _count_tokens(x):
    try:
        return len(x)
    except Exception:
        if pd.isna(x):
            return 0
        return len(str(x).split())


size_series = hinos_analise["tokens_no_stops"].apply(_count_tokens)

plot_df = pd.DataFrame(
    {
        "hino": hinos_analise.index,
        "nome": hinos_analise["nome"],
        "tamanho": size_series,
        "similaridade_media": mean_sim.loc[hinos_analise.index].astype(float),
    }
).reset_index(drop=True)

# calcula correla√ß√£o e ajuste linear
mask = np.isfinite(plot_df["tamanho"]) & np.isfinite(plot_df["similaridade_media"])
corr = np.corrcoef(
    plot_df.loc[mask, "tamanho"], plot_df.loc[mask, "similaridade_media"]
)[0, 1]

# scatter + linha de regress√£o
fig = px.scatter(
    plot_df,
    x="tamanho",
    y="similaridade_media",
    hover_data=["hino", "nome"],
    labels={
        "tamanho": "N√∫mero de tokens (tamanho do hino)",
        "similaridade_media": "Similaridade m√©dia",
    },
    title="Rela√ß√£o entre tamanho do hino e similaridade m√©dia",
    width=700,
    height=450,
    color_discrete_sequence=["#6181a8"]
)
st.plotly_chart(fig)


f"""
Fica claro que a afirma√ß√£o anterior sobre hinos mais curtos terem menor similaridade se confirma aqui. Embora existam hinos
com baixo n√∫mero de tokens que apresentam similaridade m√©dia alta, a tend√™ncia geral indica que hinos mais curtos tendem a ter
menor similaridade m√©dia com os demais hinos. Isso pode ser atribu√≠do ao fato de que hinos mais curtos possuem menos conte√∫do
sem√¢ntico para capturar, o que pode resultar em embeddings menos informativos e, consequentemente, em menor similaridade 
com outros hinos.

A **Correla√ß√£o (Pearson)** entre tamanho e similaridade m√©dia √© igual a {corr:.3f}.
Isso indica uma correla√ß√£o positiva moderada, sugerindo que, em geral, hinos maiores tendem a ter similaridade m√©dia mais alta
com os demais hinos, embora existam exce√ß√µes individuais.
"""


# mostra amostra dos valores
# st.dataframe(plot_df.sort_values("tamanho").head(10).set_index("hino"))


"""
### Hinos mais semelhantes

Usando os dados de similaridade, a seguir voc√™ pode selecionar um hino para ver os mais semelhantes com base 
nos embeddings de senten√ßas.
"""

hinos_opcoes = [
    f"{num} - {row['nome']}" for num, row in hinos_analise.iterrows()
]
hino_selecionado = st.selectbox(
    "Pesquisar hino (n√∫mero ou nome)",
    options=hinos_opcoes,
    placeholder="Digite para buscar...",
    index=None,
    help="Digite o n√∫mero ou parte do nome do hino para pesquisar",
)

if hino_selecionado:
    hymn_num = int(hino_selecionado.split(" - ")[0])
    hymn_name = hinos_analise.loc[hymn_num, "nome"]

    st.metric(label="üéµ Hino", value=f"{hymn_num} ‚Äî {hymn_name}")

    similarities = list(enumerate(similarity_sentence.iloc[hymn_num]))
    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)


    results = [
        (idx, hinos_analise["nome"].iloc[idx], score) for idx, score in similarities[1:11]
    ]
    df_sim = (
        pd.DataFrame(results, columns=["hino", "nome", "similaridade"])
        .set_index("hino")
        .rename_axis("N¬∫")
    )
    df_sim["similaridade"] = df_sim["similaridade"].round(3)
    st.dataframe(
        df_sim,
        column_config={"nome": "Nome", "similaridade": "Similaridade"},
    )
else:
    st.info("Selecione um hino para ver os mais semelhantes.")

"""
## Clustering de Hinos com Embeddings de Senten√ßas

Assim como na an√°lise de embeddings de palavras, aplicamos t√©cnicas de redu√ß√£o de dimensionalidade (UMAP)
e clustering (K-Means) para visualizar e agrupar os hinos com base em seus embeddings de frases. Levando em conta
resultados da an√°lise de silhueta, optei por 9 clusters para os embeddings de frases.
"""

fig = px.scatter(
    hinos_analise,
    x="sent_umap1",
    y="sent_umap2",
    color="sent_cluster",
    hover_data=["nome"],
    # title="Clustering de Hinos com Embeddings de Senten√ßas",
    labels={"sent_umap1": "", "sent_umap2": "", "sent_cluster": "Cluster"},
    width=600,
    height=600,
)
st.plotly_chart(fig)

"""
Na an√°lise anterior, pod√≠amos observar alguns hinos bem isolados em termos de similaridade. Aqui, vemos um agrupamento
mais coeso, com menos pontos isolados. Isso sugere que os embeddings de frases capturam melhor as semelhan√ßas sem√¢nticas 
entre os hinos, permitindo uma forma√ß√£o de clusters mais definida.
"""


"""
### Termos mais frequentes por cluster

Aqui, apresentamos os termos mais frequentes em cada cluster de hinos baseado nos embeddings de frases, bem como hinos
representativos de cada cluster. 

"""


rows = []
for c in sorted(hinos_analise["sent_cluster"].unique()):
    cluster_tokens = hinos_analise.loc[
        hinos_analise["sent_cluster"] == c, "tokens_no_stops"
    ].sum()
    top_terms = [t for t, _ in Counter(cluster_tokens).most_common(8)]
    cluster_series = hinos_analise.loc[hinos_analise["sent_cluster"] == c, "nome"]
    sampled = cluster_series.sample(n=min(3, cluster_series.shape[0]))
    top_hymns = [f"{idx} - {name}" for idx, name in sampled.items()]
    rows.append(
        {
            "Cluster": c,
            "Termos": ", ".join(top_terms),
            "Hinos de exemplo": " | ".join(top_hymns),
        }
    )

df_terms = pd.DataFrame(rows).set_index("Cluster")
st.dataframe(df_terms)

"""
Embora embeddings de frases usem o texto completo dos hinos, incluindo stopwords, os termos mais frequentes em cada cluster 
ainda refletem temas centrais dos hinos agrupados. Vemos a presen√ßa de "Jesus", "Deus" e "Senhor" em todos os clusters,
sendo essas as palavras mais comuns na colet√¢nea. Outros termos frequentes, como "amor", "gl√≥ria", "aleluia" e "vida",
tamb√©m aparecem, indicando temas recorrentes nos hinos. O cluster 6, por exemplo, √© o √∫nico a destacar "sangue", sugerindo
hinos da categoria de "CLAMOR".
"""



"""
### Rela√ß√£o entre Clusters e Categorias da Colet√¢nea

Como anteriormente, usando embeddings de palavras, analisamos a distribui√ß√£o dos clusters de embeddings de senten√ßas de hinos 
em rela√ß√£o √†s categorias originais da colet√¢nea. Assim, podemos entender como os agrupamentos baseados em embeddings de frases
correspondem √†s categorias pr√©-definidas. A seguir, apresentamos uma visualiza√ß√£o que mostra a propor√ß√£o de hinos de cada 
categoria dentro de cada cluster.
"""

# tabela de conting√™ncia: categorias x clusters
ct = pd.crosstab(
    hinos_analise["categoria_abr"], hinos_analise["sent_cluster"]
).sort_index()

# Heatmap (propor√ß√µes por categoria) com anota√ß√µes dentro dos quadrados
ct_counts = ct.copy()
ct_prop = ct_counts.div(
    ct_counts.sum(axis=1), axis=0
)  # normaliza por categoria (linha)
ct_prop_pct = ct_prop * 100  # em porcentagem

x = ct.index.tolist()  # categorias
y = [str(c) for c in ct.columns]  # clusters (string para r√≥tulos)

fig_ct = px.imshow(
    ct_prop_pct.T.values,
    x=x,
    y=y,
    labels={
        "x": "Categoria da Colet√¢nea",
        "y": "Cluster (sent_cluster)",
        "color": "Propor√ß√£o (%)",
    },
    color_continuous_scale="Cividis",
    width=800,
    height=420,
)

# adicionar anota√ß√µes com porcentagem e contagem
z = ct_prop_pct.T.values
counts = ct_counts.T.values
z_max = z.max() if z.size else 0
for i_y, y_label in enumerate(y):
    for i_x, x_label in enumerate(x):
        val_pct = z[i_y, i_x]
        cnt = int(counts[i_y, i_x])
        text = f"{val_pct:.1f}%\n({cnt})"
        # escolha de cor do texto para legibilidade
        text_color = "white" if val_pct > (z_max / 2 if z_max > 0 else 0.5) else "black"
        fig_ct.add_annotation(
            x=x_label,
            y=y_label,
            text=text,
            showarrow=False,
            font=dict(color=text_color, size=11),
            xanchor="center",
            yanchor="middle",
        )

fig_ct.update_layout(margin=dict(l=40, r=40, t=40, b=40))
st.plotly_chart(fig_ct)


"""
Podemos perceber que os clusters formados pelos embeddings de frases n√£o apresentam uma correspond√™ncia direta com as categorias 
pr√©-definidas, ainda mais do que os clusters baseados em embeddings de palavras. Uma exce√ß√£o √© o cluster 5, que cont√©m mais da metade
dos hinos na categoria "SALMOS DE LOUVOR". E como vimos anteriormente, de fato o cluster 6 est√° mais relacionado √† categoria "CLAMOR".
Portanto, embora os embeddings de frases capturem o significado sem√¢ntico dos hinos, os 
agrupamentos resultantes n√£o refletem necessariamente as categorias originais da colet√¢nea. Isso sugere que os crit√©rios utilizados 
para definir as categorias da colet√¢nea podem ser diferentes dos aspectos sem√¢nticos capturados pelos embeddings de frases.

"""

# Obten√ß√£o de t√≥picos: BERTopic(embedding_model=model)
"""
## T√≥picos comuns entre os hinos

Usando a t√©cnica BERTopic, identificamos t√≥picos comuns entre os hinos com base nos embeddings de frases. Cada t√≥pico √© representado 
por um conjunto de palavras-chave que capturam o tema central dos hinos associados a esse t√≥pico. Os t√≥picos n√£o est√£o relacionados 
com os clusters anteriores, mas sim com temas sem√¢nticos extra√≠dos dos textos dos hinos.

"""

topics = {
    0: ['amor', 'me', 'meu', 'eu', 'que', 'em', 'senhor', 'mim', 'quero', 'teu'],
    1: ['gl√≥ria', 'de', 'jesus', 'que', 'vem', 'os', 'com', 'senhor', 'santo', 'rei'],
    2: ['eu', 'que', 'jesus', 'cristo', 'c√©u', 'de', 'me', 'meu', 'com', 'dia'],
    3: ['que', 'no', 'ele', 'de', 'jesus', 'deus', 'na', 'com', 'do', 'se'],
    4: ['senhor', 'teu', 'nos', 'nosso', 'n√≥s', 'nossa', 'tua', 'vidas', 'louvor', 'te'],
    5: ['ti', 'mim', 'tu', '√©s', 'minha', 'meu', 'de', 'senhor', 'em', 'vem'],
    6: ['eu', 'de', 'meu', 'hei', 'ao', 'do', 'que', 'ver', 'me', 'terra'],
    7: ['tais', 'que', 'dos', 'sossegai', 'um', 'nos', 'cristo', 'senhor', 'jesus', 'deixa'],
    8: ['sangue', 'teu', 'mim', 'estendeu', 'me', 'para', 'm√£o', 'em', 'sem', 'senhor'],
    9: ['louvai', 'senhor', 'jerusal√©m', 'aleluia', 'do', 'ao', 'nome', 'am√©m', 'dos', 'seja'],
}

rows = [
    {"T√≥pico": f"{k}", "Palavras-chave": ", ".join(v)}
    for k, v in sorted(topics.items())
]
df_topics = pd.DataFrame(rows).set_index("T√≥pico")

st.table(df_topics)

"""
Aqui podemos ver uma maior presen√ßa de stopwords entre os termos mais frequentes de cada t√≥pico, o que √© esperado
j√° que os embeddings de frases consideram o texto completo dos hinos, incluindo essas palavras. No entanto, mesmo com a presen√ßa de stopwords, 
os t√≥picos ainda refletem temas centrais da colet√¢nea. Um t√≥pico que me chamou a aten√ß√£o foi o 7, que inclui o termo "sossegai", um termo 
incomum na colet√¢nea, provavelmente relacionado a um √∫nico hino: 310 - Mestre, o mar se revolta.
"""

# - Distribui√ß√£o de t√≥picos
"""
### Distribui√ß√£o de T√≥picos nos Hinos

Utilizando os t√≥picos identificados pelo BERTopic, visualizamos a distribui√ß√£o dos hinos em rela√ß√£o a esses t√≥picos. V√°rios pontos
est√£o marcados com valor igual a -1: isso indica que esses hinos n√£o foram atribu√≠dos a nenhum t√≥pico espec√≠fico pelo modelo,
sendo considerados "outliers" ou hinos que n√£o se encaixam bem em nenhum dos t√≥picos identificados.

"""
st.info("Na legenda do gr√°fico, √© poss√≠vel clicar no t√≥pico -1 para ocultar esses pontos e melhorar a visualiza√ß√£o.")

fig = px.scatter(
    hinos_analise,
    x="sent_umap1",
    y="sent_umap2",
    color="BERT_topic",
    hover_data=["nome"],
    labels={"sent_umap1": "", "sent_umap2": "", "BERT_topic": "T√≥pico BERT"},
    width=600,
    height=600,
)
st.plotly_chart(fig)

"""
Interessantemente, podemos observar agrupamentos definidos para alguns t√≥picos, diferente do resultado da an√°lise de t√≥picos para embeddings
de palavras. Inclusive, concordam com os agrupamentos vistos nos clusters de embeddings de frases. Por exemplo, o t√≥pico 1, relacionado a "gl√≥ria" e "santo",
est√° fortemente associado ao cluster 2, que tamb√©m destaca esses termos. Da mesma forma, o t√≥pico 2, centrado em "Jesus", "Cristo" e "c√©u", corresponde ao cluster 8,
que tamb√©m enfatiza esses temas. Essa concord√¢ncia sugere que os t√≥picos extra√≠dos pelos embeddings de frases capturam aspectos sem√¢nticos semelhantes aos
identificados pelos clusters, refor√ßando a validade dos agrupamentos observados.

"""